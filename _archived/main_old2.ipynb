{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process as fuzz_process\n",
    "from rapidfuzz import fuzz as fuzz_fuzz\n",
    "from underthesea import word_tokenize\n",
    "from LLM import Process_LLM\n",
    "import unicodedata\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.replace('đ', 'd').replace('Đ', 'D')\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "def extract_keywords(s):\n",
    "    def is_number(s):\n",
    "        return bool(re.fullmatch(r'[\\d,. ]+', s))\n",
    "    specialchars = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '..', '...', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "    specialwords = [\"giấy tờ\", \"thủ tục\", \"giấy\", \"gì\", \"cần\", \"nào\", \"sắp\", \"đang\", \"sẽ\", \"của\", \"bị\", \"hoặc\", \"với\", \"và\", \"thì\", \"muốn\"]\n",
    "    words = word_tokenize(s)\n",
    "    words = [w.lower().strip() for w in words]\n",
    "    words = list(set(words))\n",
    "    words = [w for w in words if not is_number(w)]\n",
    "    words = [w for w in words if w not in specialchars]\n",
    "    words = [w for w in words if w not in specialwords]\n",
    "    words_normalized = [normalize_text(w) for w in words if \" \" in w]\n",
    "    return words + words_normalized\n",
    "\n",
    "with open('url/cache', mode='r', newline='', encoding='utf-8') as f:\n",
    "    thutucs = csv.DictReader(f)\n",
    "    thutucs = sorted(thutucs, key=lambda e: len(e[\"Tên thủ tục\"]))\n",
    "    for i in range(len(thutucs)):\n",
    "        thutucs[i]['keywords'] = extract_keywords(thutucs[i]['Tên thủ tục'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = [\n",
    "\"sắp khởi nghiệp cần giấy tờ gì\",\n",
    "\"tôi muốn mua đất thì cần gì\",\n",
    "\"tôi sắp lập gia đình thì cần làm gì\",\n",
    "\"vợ tôi sắp sinh con thủ tục nào\",\n",
    "\"thủ tục xây nhà cấp 3, 4\",\n",
    "\"phúc khảo bài thi thpt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in test_str:\n",
    "    # ====================================================================================================\n",
    "    prompt = f\"\"\"\\\n",
    "    Câu hỏi: \"{question}\".\n",
    "    Tên của văn bản thủ tục hành chính quan trọng nhất liên quan đến câu hỏi trên là gì?\n",
    "    Trả lời ngắn gọn, không dài dòng, không giải thích, không văn bản thừa.\n",
    "    \"\"\"\n",
    "    llm_res = Process_LLM(prompt, vendor=\"openrouter\").lower().strip(string.punctuation + string.whitespace)\n",
    "\n",
    "    def find_the_best_thutucs(question):\n",
    "        q_keywords = extract_keywords(question)\n",
    "        thutuc_scores = []\n",
    "        for e in thutucs:\n",
    "            # count 1: keywords\n",
    "            count = 0\n",
    "            for k in q_keywords:\n",
    "                if k in e[\"keywords\"]:\n",
    "                    count += 1\n",
    "            # count 2: full name\n",
    "            if normalize_text(question) in normalize_text(e[\"Tên thủ tục\"]):\n",
    "                count += 1\n",
    "                if question.lower() in e[\"Tên thủ tục\"].lower():\n",
    "                    count += 1\n",
    "            thutuc_scores.append(count)\n",
    "        thutuc_scores_idx = sorted(range(len(thutuc_scores)), key=lambda i: thutuc_scores[i], reverse=True)\n",
    "        scores = [(idx, thutuc_scores[idx]) for idx in thutuc_scores_idx]\n",
    "        scores = [e for e in scores if e[1] != 0]\n",
    "        # Return\n",
    "        for i in range(min(len(scores), 3)):\n",
    "            print(f\"{thutucs[scores[i][0]]['Tên thủ tục']} (score={scores[i][1]})\")\n",
    "\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"llm_res: {llm_res}\")\n",
    "    print(\"-\"*50)\n",
    "    find_the_best_thutucs(question)\n",
    "    print(\"-\"*50)\n",
    "    fuz_res = [(ee[2], ee[1]) for ee in fuzz_process.extract(llm_res, [e[\"Tên thủ tục\"].lower().strip() for e in thutucs], scorer=fuzz_fuzz.token_set_ratio, limit=3)]\n",
    "    for i in range(len(fuz_res)):\n",
    "        print(f\"{thutucs[fuz_res[i][0]]['Tên thủ tục']} (score={fuz_res[i][1]})\")\n",
    "    print(\"-\"*50)\n",
    "    find_the_best_thutucs(llm_res)\n",
    "    print(\"=\"*100)\n",
    "    # ===================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
